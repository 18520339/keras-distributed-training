{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T02:21:02.256777Z",
     "iopub.status.busy": "2022-01-14T02:21:02.256117Z",
     "iopub.status.idle": "2022-01-14T02:21:04.257780Z",
     "shell.execute_reply": "2022-01-14T02:21:04.257168Z"
    },
    "id": "vHNvttzV43sA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-worker configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(gpu_devices) == 0: raise SystemError('GPU device not found')\n",
    "for gpu in gpu_devices: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_config = {\n",
    "    'cluster': {\n",
    "        'worker': ['192.168.1.1:12345', '192.168.1.16:12345']\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': 0}\n",
    "}\n",
    "os.environ.pop('TF_CONFIG', None)\n",
    "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MultiWorkerMirroredStrategy(\n",
    "    communication_options = tf.distribute.experimental.CommunicationOptions(\n",
    "        implementation = tf.distribute.experimental.CollectiveCommunication.RING\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "PER_WORKER_BATCH_SIZE = 32\n",
    "NUM_WORKERS = len(tf_config['cluster']['worker'])\n",
    "GLOBAL_BATCH_SIZE = PER_WORKER_BATCH_SIZE * NUM_WORKERS\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Rescaling\n",
    "data_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "data_root = tf.keras.utils.get_file('flower_photos', data_url, untar=True)\n",
    "data_length = !find {data_root} -name *.jpg | wc -l\n",
    "data_length = int(data_length[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(batch_size, subset):\n",
    "    shuffle = False\n",
    "    if subset == 'validation': length = int(data_length * 0.2)\n",
    "    elif subset == 'training': \n",
    "        length = int(data_length * 0.8)\n",
    "        shuffle = True\n",
    "    else: \n",
    "        raise NameError(\"subset must be 'training' or 'validation'\")\n",
    "        \n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "      str(data_root),\n",
    "      validation_split = 0.2,\n",
    "      subset = subset,\n",
    "      image_size = IMAGE_SIZE,\n",
    "      batch_size = batch_size,\n",
    "      seed = 123,\n",
    "    )\n",
    "    normalization_layer = Rescaling(1./127.5, offset=-1)\n",
    "    dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "    \n",
    "    if shuffle: dataset = dataset.shuffle(buffer_size=length)\n",
    "    dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, num_train = get_dataset(GLOBAL_BATCH_SIZE, 'training')\n",
    "ds_val, num_val = get_dataset(GLOBAL_BATCH_SIZE, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model():\n",
    "    feature_extractor_layer = hub.KerasLayer(\n",
    "        'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4',\n",
    "        input_shape = IMAGE_SIZE + (3,),\n",
    "        trainable = True\n",
    "    )\n",
    "    model = Sequential([feature_extractor_layer, Dense(5)])\n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope(): \n",
    "    model = build_and_compile_model()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay(epoch):\n",
    "    if epoch < 3: return 1e-3\n",
    "    elif epoch >= 3 and epoch < 7: return 1e-4\n",
    "    return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback for printing the learning rate at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f'\\nLearning rate for epoch {epoch + 1} is {model.optimizer.lr.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, LearningRateScheduler\n",
    "callbacks = [\n",
    "    TensorBoard(log_dir='./logs'),\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1),\n",
    "    LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    ds_train, \n",
    "    validation_data = ds_val,\n",
    "    callbacks = callbacks,\n",
    "    epochs = EPOCHS, \n",
    "    verbose = 1,\n",
    ")\n",
    "%tensorboard --logdir=logs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multi_worker_with_keras.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
